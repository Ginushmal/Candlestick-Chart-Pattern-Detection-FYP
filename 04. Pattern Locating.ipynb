{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:2: SyntaxWarning: invalid escape sequence '\\V'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\V'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "C:\\Users\\gwiku\\AppData\\Local\\Temp\\ipykernel_34596\\2234204653.py:2: SyntaxWarning: invalid escape sequence '\\V'\n",
      "  X_test = pd.read_csv('Datasets\\VanilaDataset\\X-Y Splitted Data\\X_test.csv')\n",
      "C:\\Users\\gwiku\\AppData\\Local\\Temp\\ipykernel_34596\\2234204653.py:3: SyntaxWarning: invalid escape sequence '\\V'\n",
      "  y_test = pd.read_csv('Datasets\\VanilaDataset\\X-Y Splitted Data\\y_test.csv')\n"
     ]
    }
   ],
   "source": [
    "# import X_test and y_test\n",
    "X_test = pd.read_csv('Datasets\\VanilaDataset\\X-Y Splitted Data\\X_test.csv')\n",
    "y_test = pd.read_csv('Datasets\\VanilaDataset\\X-Y Splitted Data\\y_test.csv')\n",
    "\n",
    "# 1st column in these dataets are the level 1 index , and the 2nd column is the level 2 index , set them as such\n",
    "X_test = X_test.set_index(['Instance', 'Time'])  \n",
    "y_test = y_test.set_index(['Instance'])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instance</th>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">0</th>\n",
       "      <th>0</th>\n",
       "      <td>0.210031</td>\n",
       "      <td>0.394983</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.371473</td>\n",
       "      <td>0.517012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.570534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.434168</td>\n",
       "      <td>0.457681</td>\n",
       "      <td>0.021450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.437304</td>\n",
       "      <td>0.437304</td>\n",
       "      <td>0.067397</td>\n",
       "      <td>0.297805</td>\n",
       "      <td>0.118713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.506270</td>\n",
       "      <td>0.705330</td>\n",
       "      <td>0.429466</td>\n",
       "      <td>0.551723</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.626960</td>\n",
       "      <td>0.974921</td>\n",
       "      <td>0.605014</td>\n",
       "      <td>0.846395</td>\n",
       "      <td>0.087648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">557</th>\n",
       "      <th>2</th>\n",
       "      <td>0.171173</td>\n",
       "      <td>0.513513</td>\n",
       "      <td>0.162162</td>\n",
       "      <td>0.360362</td>\n",
       "      <td>0.822514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.297299</td>\n",
       "      <td>0.630631</td>\n",
       "      <td>0.297299</td>\n",
       "      <td>0.468469</td>\n",
       "      <td>0.328470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.504505</td>\n",
       "      <td>0.720720</td>\n",
       "      <td>0.396398</td>\n",
       "      <td>0.675675</td>\n",
       "      <td>0.397136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.567568</td>\n",
       "      <td>0.639642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396398</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.414417</td>\n",
       "      <td>0.846849</td>\n",
       "      <td>0.324325</td>\n",
       "      <td>0.684686</td>\n",
       "      <td>0.490831</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14385 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Open      High       Low     Close    Volume\n",
       "Instance Time                                                  \n",
       "0        0     0.210031  0.394983  0.000000  0.371473  0.517012\n",
       "         1     0.570534  1.000000  0.434168  0.457681  0.021450\n",
       "         2     0.437304  0.437304  0.067397  0.297805  0.118713\n",
       "         3     0.506270  0.705330  0.429466  0.551723  0.000000\n",
       "         4     0.626960  0.974921  0.605014  0.846395  0.087648\n",
       "...                 ...       ...       ...       ...       ...\n",
       "557      2     0.171173  0.513513  0.162162  0.360362  0.822514\n",
       "         3     0.297299  0.630631  0.297299  0.468469  0.328470\n",
       "         4     0.504505  0.720720  0.396398  0.675675  0.397136\n",
       "         5     0.567568  0.639642  0.000000  0.396398  0.000000\n",
       "         6     0.414417  0.846849  0.324325  0.684686  0.490831\n",
       "\n",
       "[14385 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pattern</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Instance</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>553</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>558 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Pattern\n",
       "Instance         \n",
       "0               1\n",
       "1               3\n",
       "2               1\n",
       "3               4\n",
       "4               0\n",
       "...           ...\n",
       "553             2\n",
       "554             1\n",
       "555             0\n",
       "556             2\n",
       "557             4\n",
       "\n",
       "[558 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(275, 4, 24.933691756272403)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# max min and avg lengths of Instance index sets in X_test\n",
    "max_len = 0\n",
    "min_len = 100000\n",
    "sum_len = 0\n",
    "for i in range(1, 538):\n",
    "    len_i = len(X_test.loc[i])\n",
    "    sum_len += len_i\n",
    "    if len_i > max_len:\n",
    "        max_len = len_i\n",
    "    if len_i < min_len:\n",
    "        min_len = len_i\n",
    "        \n",
    "avg_len = sum_len / len(y_test)\n",
    "max_len, min_len, avg_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  load test_patterns_with_symbols.csv and train_patterns_with_symbols.csv\n",
    "test_patterns = pd.read_csv('Datasets/VanilaDataset/test_patterns_with_symbols.csv')\n",
    "train_patterns = pd.read_csv('Datasets/VanilaDataset/train_patterns_with_symbols.csv')\n",
    "\n",
    "# convert the Start and End columns to datetime\n",
    "test_patterns['Start'] = pd.to_datetime(test_patterns['Start'])\n",
    "test_patterns['End'] = pd.to_datetime(test_patterns['End'])\n",
    "train_patterns['Start'] = pd.to_datetime(train_patterns['Start'])\n",
    "train_patterns['End'] = pd.to_datetime(train_patterns['End'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Chart Pattern</th>\n",
       "      <th>BullishBearish</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMG</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>Chemical (Basic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLF</td>\n",
       "      <td>Head-and-shoulders top</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>Metals and Mining (Div.)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>Diversified Co.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT</td>\n",
       "      <td>Double Bottom, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>IT Services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAZZ</td>\n",
       "      <td>Double Top, Adam and Adam</td>\n",
       "      <td>-1</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>Biotechnology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>K</td>\n",
       "      <td>Double Bottom, Eve and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>Food Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>ADM</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>Food Processing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>HQY</td>\n",
       "      <td>Double Top, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>Healthcare Information</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>LZB</td>\n",
       "      <td>Double Bottom, Eve and Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>Furn/Home Furnishings</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>OGE</td>\n",
       "      <td>Double Bottom, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>Electric Utility (Central)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>559 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol                 Chart Pattern  BullishBearish      Start  \\\n",
       "0      SMG         Triangle, symmetrical               1 2021-10-06   \n",
       "1      CLF        Head-and-shoulders top               0 2024-03-01   \n",
       "2       CR         Triangle, symmetrical               0 2023-07-28   \n",
       "3       IT  Double Bottom, Adam and Adam               0 2022-10-13   \n",
       "4     JAZZ     Double Top, Adam and Adam              -1 2022-07-07   \n",
       "..     ...                           ...             ...        ...   \n",
       "554      K   Double Bottom, Eve and Adam               0 2024-07-09   \n",
       "555    ADM         Triangle, symmetrical               1 2020-10-23   \n",
       "556    HQY     Double Top, Adam and Adam               0 2024-07-17   \n",
       "557    LZB   Double Bottom, Eve and Adam               1 2021-12-01   \n",
       "558    OGE  Double Bottom, Adam and Adam               0 2023-08-15   \n",
       "\n",
       "           End                    Industry  \n",
       "0   2021-10-21            Chemical (Basic)  \n",
       "1   2024-03-13    Metals and Mining (Div.)  \n",
       "2   2023-09-28             Diversified Co.  \n",
       "3   2022-10-21                 IT Services  \n",
       "4   2022-07-28               Biotechnology  \n",
       "..         ...                         ...  \n",
       "554 2024-07-15             Food Processing  \n",
       "555 2020-12-02             Food Processing  \n",
       "556 2024-07-26      Healthcare Information  \n",
       "557 2021-12-20       Furn/Home Furnishings  \n",
       "558 2023-08-21  Electric Utility (Central)  \n",
       "\n",
       "[559 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_patterns.loc[3, 'Symbol'] == train_patterns.loc[3, 'Symbol']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intersection Percentage: 76.47058823529412\n",
      "Dropping test row with index: 20\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 24\n",
      "Intersection Percentage: 0.46728971962616817\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 55\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 72\n",
      "Intersection Percentage: 10.204081632653061\n",
      "Intersection Percentage: 10.204081632653061\n",
      "Intersection Percentage: 10.204081632653061\n",
      "Intersection Percentage: 87.5\n",
      "Dropping test row with index: 79\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 107\n",
      "Intersection Percentage: 92.3076923076923\n",
      "Dropping test row with index: 113\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 116\n",
      "Intersection Percentage: 2.898550724637681\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 155\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 160\n",
      "Intersection Percentage: 95.23809523809523\n",
      "Dropping test row with index: 161\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 166\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 167\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 179\n",
      "Intersection Percentage: 5.1020408163265305\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 189\n",
      "Intersection Percentage: 42.567567567567565\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 206\n",
      "Intersection Percentage: 35.41666666666667\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 227\n",
      "Intersection Percentage: 24.137931034482758\n",
      "Intersection Percentage: 19.51219512195122\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 253\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 275\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 294\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 335\n",
      "Intersection Percentage: 17.94871794871795\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 390\n",
      "Intersection Percentage: 94.11764705882352\n",
      "Dropping test row with index: 425\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 430\n",
      "Intersection Percentage: 8.522727272727272\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 460\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 478\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 483\n",
      "Intersection Percentage: 22.22222222222222\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 533\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 545\n",
      "Intersection Percentage: 100.0\n",
      "Dropping test row with index: 553\n",
      "Dropped row count: 30\n"
     ]
    }
   ],
   "source": [
    "drop_count = 0\n",
    "for i in range(len(test_patterns)):\n",
    "    for j in range(len(train_patterns)):\n",
    "        # Check if the time intervals intersect and belong to the same symbol\n",
    "        if (\n",
    "            test_patterns.loc[i, 'Start'] < train_patterns.loc[j, 'End'] and\n",
    "            test_patterns.loc[i, 'End'] > train_patterns.loc[j, 'Start'] and\n",
    "            test_patterns.loc[i, 'Symbol'] == train_patterns.loc[j, 'Symbol']\n",
    "        ):\n",
    "            # Calculate the intersection range\n",
    "            intersection_start = max(test_patterns.loc[i, 'Start'], train_patterns.loc[j, 'Start'])\n",
    "            intersection_end = min(test_patterns.loc[i, 'End'], train_patterns.loc[j, 'End'])\n",
    "            intersection_length = (intersection_end - intersection_start).days  # Length in days\n",
    "\n",
    "            # Calculate train segment length\n",
    "            train_length = (train_patterns.loc[j, 'End'] - train_patterns.loc[j, 'Start']).days\n",
    "\n",
    "            # Calculate the percentage of interaction\n",
    "            interaction_percentage = (intersection_length / train_length) * 100\n",
    "\n",
    "            print('Intersection Percentage:', interaction_percentage)\n",
    "\n",
    "            # Drop the test row if interaction percentage > 60%\n",
    "            if interaction_percentage > 60:\n",
    "                print('Dropping test row with index:', i)\n",
    "                test_patterns = test_patterns.drop(i)\n",
    "                drop_count += 1\n",
    "                break\n",
    "            \n",
    "print ('Dropped row count:', drop_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "529"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing row 559/529: Current pattern start: 2023-08-15 00:00:00, end: 2023-08-21 00:00:00, intersection: 1 dayss\n",
      "Processing complete.\n"
     ]
    }
   ],
   "source": [
    "new_combined_test_ohcl_df = []  # Initialize as a list to collect rows\n",
    "\n",
    "extend_length = 50  # Number of days to extend the pattern\n",
    "\n",
    "for index, row in test_patterns.iterrows():\n",
    "    current_pattern_start_date = row['Start']\n",
    "    current_pattern_end_date = row['End']\n",
    "    \n",
    "    # Add and subtract 300 days to get the new start and end dates\n",
    "    new_pattern_end_date = current_pattern_end_date + pd.DateOffset(days=extend_length)\n",
    "    new_pattern_start_date = current_pattern_start_date - pd.DateOffset(days=extend_length)\n",
    "    \n",
    "    print(f\"Processing row {index + 1}/{len(test_patterns)}: Current pattern start: {current_pattern_start_date}, end: {current_pattern_end_date}\", end=\"\\r\")\n",
    "    \n",
    "    for j in range(len(train_patterns)):\n",
    "        train_start = train_patterns.loc[j, 'Start']\n",
    "        train_end = train_patterns.loc[j, 'End']\n",
    "        train_length = (train_end - train_start).days  # Train segment length in days\n",
    "        \n",
    "        # Calculate allowed intersection length (60%)\n",
    "        allowed_intersection = train_length * 0.6\n",
    "        \n",
    "        # if the new pattern intersects with the train pattern\n",
    "        if (\n",
    "            new_pattern_start_date < train_end and\n",
    "            new_pattern_end_date > train_start and\n",
    "            row['Symbol'] == train_patterns.loc[j, 'Symbol']\n",
    "        ):\n",
    "            # Calculate the intersection range\n",
    "            intersection_start = max(new_pattern_start_date, train_start)\n",
    "            intersection_end = min(new_pattern_end_date, train_end)\n",
    "            intersection_length = (intersection_end - intersection_start).days\n",
    "            \n",
    "            print(\n",
    "                f\"Checking train pattern {j + 1}/{len(train_patterns)}: Train start: {train_start}, end: {train_end}, intersection: {intersection_length} days\",\n",
    "                end=\"\\r\"\n",
    "            )\n",
    "            \n",
    "            inter_perc = (intersection_length / train_length) * 100\n",
    "            \n",
    "            # if the intersection length is greater than 60% of the train pattern length\n",
    "            if intersection_length > allowed_intersection:\n",
    "                incremental_update_start_date = current_pattern_start_date\n",
    "                incremental_update_end_date = current_pattern_end_date\n",
    "                incr_intercal_length = 0\n",
    "                \n",
    "                while incr_intercal_length < allowed_intersection:\n",
    "                    # change the start and end dates of the section by 1 day\n",
    "                    incremental_update_start_date = incremental_update_start_date - pd.DateOffset(days=1)\n",
    "                    incremental_update_end_date = incremental_update_end_date + pd.DateOffset(days=1)\n",
    "                    \n",
    "                    print(\n",
    "                            f\"Updated incrementally: Start: {incremental_update_start_date}, End: {incremental_update_end_date}\",\n",
    "                            end=\"\\r\"\n",
    "                        )\n",
    "\n",
    "                    # cheeck if the new section intersects with the train pattern\n",
    "                    if incremental_update_start_date < train_end and incremental_update_end_date > train_start:\n",
    "                        incr_intercal_start = max(incremental_update_start_date, train_start)\n",
    "                        incr_intercal_end = min(incremental_update_end_date, train_end)\n",
    "                        incr_intercal_length = (incr_intercal_end - incr_intercal_start).days\n",
    "                        \n",
    "                    # if the intersection length is greater than 60% of the train pattern length undo the last change and break\n",
    "                    if incr_intercal_length > allowed_intersection:\n",
    "                        incremental_update_start_date = incremental_update_start_date + pd.DateOffset(days=1)\n",
    "                        incremental_update_end_date = incremental_update_end_date - pd.DateOffset(days=1)\n",
    "                        break\n",
    "                    # if somehow the new section is the same as the old 300 days changed section break\n",
    "                    elif incremental_update_start_date == new_pattern_start_date and incremental_update_end_date == new_pattern_end_date:\n",
    "                        break\n",
    "                \n",
    "                        \n",
    "                new_pattern_start_date = incremental_update_start_date\n",
    "                new_pattern_end_date = incremental_update_end_date\n",
    "                    \n",
    "    # add two new column test_sec_start and test_sec_end to row and append it to new_combined_test_ohcl_df\n",
    "    row['test_sec_start'] = new_pattern_start_date\n",
    "    row['test_sec_end'] = new_pattern_end_date\n",
    "    \n",
    "    new_combined_test_ohcl_df.append(row)\n",
    "\n",
    "# Convert the result list to a DataFrame\n",
    "new_combined_test_ohcl_df = pd.DataFrame(new_combined_test_ohcl_df)\n",
    "print(\"\\nProcessing complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Chart Pattern</th>\n",
       "      <th>BullishBearish</th>\n",
       "      <th>Start</th>\n",
       "      <th>End</th>\n",
       "      <th>Industry</th>\n",
       "      <th>test_sec_start</th>\n",
       "      <th>test_sec_end</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SMG</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>2021-10-21</td>\n",
       "      <td>Chemical (Basic)</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>2021-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CLF</td>\n",
       "      <td>Head-and-shoulders top</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-03-01</td>\n",
       "      <td>2024-03-13</td>\n",
       "      <td>Metals and Mining (Div.)</td>\n",
       "      <td>2024-01-11</td>\n",
       "      <td>2024-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CR</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-07-28</td>\n",
       "      <td>2023-09-28</td>\n",
       "      <td>Diversified Co.</td>\n",
       "      <td>2023-06-08</td>\n",
       "      <td>2023-11-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>IT</td>\n",
       "      <td>Double Bottom, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2022-10-13</td>\n",
       "      <td>2022-10-21</td>\n",
       "      <td>IT Services</td>\n",
       "      <td>2022-08-24</td>\n",
       "      <td>2022-12-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JAZZ</td>\n",
       "      <td>Double Top, Adam and Adam</td>\n",
       "      <td>-1</td>\n",
       "      <td>2022-07-07</td>\n",
       "      <td>2022-07-28</td>\n",
       "      <td>Biotechnology</td>\n",
       "      <td>2022-05-18</td>\n",
       "      <td>2022-09-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>554</th>\n",
       "      <td>K</td>\n",
       "      <td>Double Bottom, Eve and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-09</td>\n",
       "      <td>2024-07-15</td>\n",
       "      <td>Food Processing</td>\n",
       "      <td>2024-06-27</td>\n",
       "      <td>2024-07-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>ADM</td>\n",
       "      <td>Triangle, symmetrical</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>2020-12-02</td>\n",
       "      <td>Food Processing</td>\n",
       "      <td>2020-09-03</td>\n",
       "      <td>2021-01-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>HQY</td>\n",
       "      <td>Double Top, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2024-07-17</td>\n",
       "      <td>2024-07-26</td>\n",
       "      <td>Healthcare Information</td>\n",
       "      <td>2024-05-28</td>\n",
       "      <td>2024-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>LZB</td>\n",
       "      <td>Double Bottom, Eve and Adam</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-12-01</td>\n",
       "      <td>2021-12-20</td>\n",
       "      <td>Furn/Home Furnishings</td>\n",
       "      <td>2021-10-12</td>\n",
       "      <td>2022-02-08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>558</th>\n",
       "      <td>OGE</td>\n",
       "      <td>Double Bottom, Adam and Adam</td>\n",
       "      <td>0</td>\n",
       "      <td>2023-08-15</td>\n",
       "      <td>2023-08-21</td>\n",
       "      <td>Electric Utility (Central)</td>\n",
       "      <td>2023-06-26</td>\n",
       "      <td>2023-10-10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>529 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Symbol                 Chart Pattern  BullishBearish      Start  \\\n",
       "0      SMG         Triangle, symmetrical               1 2021-10-06   \n",
       "1      CLF        Head-and-shoulders top               0 2024-03-01   \n",
       "2       CR         Triangle, symmetrical               0 2023-07-28   \n",
       "3       IT  Double Bottom, Adam and Adam               0 2022-10-13   \n",
       "4     JAZZ     Double Top, Adam and Adam              -1 2022-07-07   \n",
       "..     ...                           ...             ...        ...   \n",
       "554      K   Double Bottom, Eve and Adam               0 2024-07-09   \n",
       "555    ADM         Triangle, symmetrical               1 2020-10-23   \n",
       "556    HQY     Double Top, Adam and Adam               0 2024-07-17   \n",
       "557    LZB   Double Bottom, Eve and Adam               1 2021-12-01   \n",
       "558    OGE  Double Bottom, Adam and Adam               0 2023-08-15   \n",
       "\n",
       "           End                    Industry test_sec_start test_sec_end  \n",
       "0   2021-10-21            Chemical (Basic)     2021-08-17   2021-12-10  \n",
       "1   2024-03-13    Metals and Mining (Div.)     2024-01-11   2024-05-02  \n",
       "2   2023-09-28             Diversified Co.     2023-06-08   2023-11-17  \n",
       "3   2022-10-21                 IT Services     2022-08-24   2022-12-10  \n",
       "4   2022-07-28               Biotechnology     2022-05-18   2022-09-16  \n",
       "..         ...                         ...            ...          ...  \n",
       "554 2024-07-15             Food Processing     2024-06-27   2024-07-27  \n",
       "555 2020-12-02             Food Processing     2020-09-03   2021-01-21  \n",
       "556 2024-07-26      Healthcare Information     2024-05-28   2024-09-14  \n",
       "557 2021-12-20       Furn/Home Furnishings     2021-10-12   2022-02-08  \n",
       "558 2023-08-21  Electric Utility (Central)     2023-06-26   2023-10-10  \n",
       "\n",
       "[529 rows x 8 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_combined_test_ohcl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2000-05-04 00:00:00')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "origin_date = pd.to_datetime(\"2000-01-01\")\n",
    "test_sec_start_date = pd.to_datetime(\"2023-10-29\")\n",
    "test_sec_end_date = pd.to_datetime(\"2024-07-15\")\n",
    "test_start_date = pd.to_datetime(\"2024-03-01\")\n",
    "origin_date + (test_start_date- test_sec_start_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('124 days 00:00:00')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_start_date -test_sec_start_date "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_new_combined_test_ohcl_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtest_new_combined_test_ohcl_df\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_new_combined_test_ohcl_df' is not defined"
     ]
    }
   ],
   "source": [
    "test_new_combined_test_ohcl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohcl_data_current = pd.read_csv(\"Datasets/OHLS data/CLF.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ohcl_data_current[\"Date\"] = pd.to_datetime(ohcl_data_current[\"Date\"])\n",
    "ohcl_data_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohcl_data_current[\"Date\"].iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the rows between start and end date sections of the row\n",
    "ohcl_data_current = ohcl_data_current[\n",
    "    (ohcl_data_current[\"Date\"] >= test_sec_start_date) & (ohcl_data_current[\"Date\"] <= test_sec_end_date)\n",
    "]\n",
    "\n",
    "ohcl_data_current.reset_index(drop=True, inplace=True)\n",
    "ohcl_data_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff=ohcl_data_current[\"Date\"].iloc[0] - origin_date\n",
    "date_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff= -87558\n",
    "# convert date_diff to days\n",
    "date_diff = date_diff.days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff= -87558\n",
    "# convert date_diff to days\n",
    "date_diff = date_diff.days\n",
    "ohcl_data_current[\"Date\"] = ohcl_data_current[\"Date\"] - date_diff\n",
    "ohcl_data_current"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row = new_combined_test_ohcl_df.iloc[1:2]\n",
    "# convert the start and end dates to datetime\n",
    "row['test_sec_start'] = pd.to_datetime(row['test_sec_start'])\n",
    "row['test_sec_end'] = pd.to_datetime(row['test_sec_end'])   \n",
    "row['Start'] = pd.to_datetime(row['Start'])\n",
    "row['End'] = pd.to_datetime(row['End'])\n",
    "row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate synthetic stream dates\n",
    "synth_pattern_start = origin_date + (row[\"Start\"] - row[\"test_sec_start\"])\n",
    "synth_pattern_end = origin_date + (row[\"End\"] - row[\"test_sec_start\"])\n",
    "\n",
    "origin_date = origin_date + (row[\"test_sec_end\"] - row[\"test_sec_start\"])\n",
    "\n",
    "print ((row[\"Start\"] - row[\"test_sec_start\"]) , (row[\"End\"] - row[\"test_sec_start\"]) , (row[\"test_sec_end\"] - row[\"test_sec_start\"]))\n",
    "print (synth_pattern_start, synth_pattern_end, origin_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write a code to substract two given string dates and return the difference in days\n",
    "def date_diff(date1, date2):\n",
    "    date1 = pd.to_datetime(date1)\n",
    "    date2 = pd.to_datetime(date2)\n",
    "    \n",
    "    return (date2 - date1).days\n",
    "\n",
    "def date_sum(date, days):\n",
    "    date = pd.to_datetime(date)\n",
    "    \n",
    "    return date + pd.DateOffset(days=days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#  loop through each row of new_combined_test_ohcl_df and create a new OHCL DataFrame with the corresponding OHCL data combined\n",
    "OHCL_combined_df = pd.DataFrame()\n",
    "test_stream_patterns = pd.DataFrame()\n",
    "origin_date = pd.to_datetime(\"1800-01-01\")\n",
    "\n",
    "# get the 2nt row of new_combined_test_ohcl_df as the test_new_combined_test_ohcl_df DataFrame\n",
    "test_new_combined_test_ohcl_df = new_combined_test_ohcl_df.iloc[0:6]\n",
    "\n",
    "for i , row in new_combined_test_ohcl_df.iterrows():\n",
    "    symbol = row[\"Symbol\"]\n",
    "    #  read the OHCL file\n",
    "    ohcl_data_current = pd.read_csv(\"Datasets/OHLS data/\" + symbol + \".csv\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  convert the Date column to datetime\n",
    "    ohcl_data_current[\"Date\"] = pd.to_datetime(ohcl_data_current[\"Date\"])\n",
    "    \n",
    "    # get the rows between start and end date sections of the row\n",
    "    ohcl_data_current = ohcl_data_current[\n",
    "        (ohcl_data_current[\"Date\"] >= row[\"test_sec_start\"]) & (ohcl_data_current[\"Date\"] <= row[\"test_sec_end\"])\n",
    "    ]\n",
    "    \n",
    "    ohcl_data_current.reset_index(drop=True, inplace=True)\n",
    "    # print the ohcl_data_current dataframe and cleear it when the next one is printed\n",
    "    print(ohcl_data_current)\n",
    "    # If the DataFrame is empty, skip this iteration\n",
    "    if ohcl_data_current.empty:\n",
    "        print(f\"No data for symbol {symbol} between {row['test_sec_start']} and {row['test_sec_end']}\")\n",
    "        continue\n",
    "    \n",
    "    # update all the dates in ohcl_data_current Date column to the corresponding synthetic stream dates starting from origin_date\n",
    "    # to do that get the date difference between the first date in ohcl_data_current and the origin_date\n",
    "    date_diff = ohcl_data_current[\"Date\"].iloc[0] - origin_date\n",
    "    \n",
    "    # print ohcl_data_current[\"Date\"].iloc[0] and origin_date and the difference \n",
    "    print(\"ohcl data current date:\", str(ohcl_data_current[\"Date\"].iloc[0]) , \"origin date:\", origin_date , \"difference:\", date_diff)\n",
    "    \n",
    "    # now reduce this date_diff from all the dates in the Date column\n",
    "    ohcl_data_current[\"Date\"] = ohcl_data_current[\"Date\"] - date_diff\n",
    "    # ohcl_data_current[\"Date\"] = ohcl_data_current[\"Date\"].apply(lambda d: pd.Timestamp(d) - date_diff)\n",
    "\n",
    "    \n",
    "    \n",
    "    # print the ohcl_data_current dataframe and cleear it when the next one is printed\n",
    "    print(ohcl_data_current)\n",
    "    \n",
    "    \n",
    "    # combine the data to OHCL_combined_df\n",
    "    OHCL_combined_df = pd.concat([OHCL_combined_df, ohcl_data_current])\n",
    "    OHCL_combined_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    print(\"OHCL_combined_df\", OHCL_combined_df)\n",
    "    \n",
    "    # calculate synthetic stream dates\n",
    "    synth_pattern_start = origin_date + (row[\"Start\"] - row[\"test_sec_start\"])\n",
    "    synth_pattern_end = origin_date + (row[\"End\"] - row[\"test_sec_start\"])\n",
    "    \n",
    "    # get the last date of ohcl_data_current and add 1 day to it to get the origin_date for the next iteration\n",
    "    origin_date = ohcl_data_current[\"Date\"].iloc[-1] + pd.DateOffset(days=1)\n",
    "    \n",
    "    print (row)\n",
    "    print ((row[\"Start\"] - row[\"test_sec_start\"]) , (row[\"End\"] - row[\"test_sec_start\"]) , (row[\"test_sec_end\"] - row[\"test_sec_start\"]))\n",
    "    print (synth_pattern_start, synth_pattern_end, origin_date)\n",
    "    \n",
    "    row_copy = row.copy()\n",
    "    \n",
    "    row_copy[\"Synth_Start\"] = synth_pattern_start\n",
    "    row_copy[\"Synth_End\"] = synth_pattern_end\n",
    "    \n",
    "    # convert row_copy to a dataframe\n",
    "    row_copy = pd.DataFrame(row_copy).T\n",
    "    \n",
    "    test_stream_patterns = pd.concat([test_stream_patterns, row_copy])\n",
    "    \n",
    "    print(\"test_stream_patterns\", test_stream_patterns)\n",
    "    \n",
    "    test_stream_patterns.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_diff(\"2000-05-04\", \"2000-05-16\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "date_sum(\"2000-09-17\", 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OHCL_combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_stream_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  from test_stream_patterns drop Start , End , test_sec_start and test_sec_end columns\n",
    "test_stream_patterns = test_stream_patterns.drop(columns=['Start', 'End', 'test_sec_start', 'test_sec_end'])\n",
    "# rename Synth_Start and Synth_End columns to Start and End\n",
    "test_stream_patterns.rename(columns={\"Synth_Start\": \"Start\", \"Synth_End\": \"End\"}, inplace=True)\n",
    "test_stream_patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "\n",
    "# Step 2: Prepare Data\n",
    "OHCL_combined_df['Date'] = pd.to_datetime(OHCL_combined_df['Date'])\n",
    "\n",
    "# Step 3: Plot Candlestick Chart\n",
    "fig = go.Figure(data=[go.Candlestick(x=OHCL_combined_df['Date'],\n",
    "                                     open=OHCL_combined_df['Open'],\n",
    "                                     high=OHCL_combined_df['High'],\n",
    "                                     low=OHCL_combined_df['Low'],\n",
    "                                     close=OHCL_combined_df['Close'])])\n",
    "\n",
    "# Step 4: Prepare test_stream_patterns\n",
    "\n",
    "test_stream_patterns['Start'] = pd.to_datetime(test_stream_patterns['Start'])\n",
    "test_stream_patterns['End'] = pd.to_datetime(test_stream_patterns['End'])\n",
    "\n",
    "# Step 5: Mark Patterns\n",
    "for index, row in test_stream_patterns.iterrows():\n",
    "\n",
    "    start_date = row['Start']\n",
    "    end_date = row['End']\n",
    "    pattern = row['Chart Pattern']\n",
    "    color = 'rgba(0, 0, 255, 0.2)' if row['BullishBearish'] == 'Bullish' else 'rgba(255, 0, 0, 0.2)'\n",
    "    \n",
    "    # Add shaded area for pattern range\n",
    "    fig.add_shape(\n",
    "        type=\"rect\",\n",
    "        xref=\"x\",\n",
    "        yref=\"paper\",\n",
    "        x0=start_date,\n",
    "        y0=0,\n",
    "        x1=end_date,\n",
    "        y1=1,\n",
    "        fillcolor=color,\n",
    "        opacity=0.2,\n",
    "        layer=\"below\",\n",
    "        line_width=0,\n",
    "    )\n",
    "    \n",
    "    # Add annotation for pattern\n",
    "    fig.add_annotation(x=start_date, y=OHCL_combined_df['High'].max(), text=pattern, showarrow=True, arrowhead=1)\n",
    "\n",
    "# Step 6: Adjust Layout for Height and Zoom Controls\n",
    "fig.update_layout(\n",
    "    title='Test Stream Candlestick Chart with Pattern Annotations',\n",
    "    height=800,\n",
    "    autosize=True,\n",
    "    yaxis={'fixedrange': False},\n",
    "    xaxis={'fixedrange': False, 'rangeslider': {'visible': True}}\n",
    ")\n",
    "\n",
    "# Step 7: Display Chart\n",
    "fig.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "FYPenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
